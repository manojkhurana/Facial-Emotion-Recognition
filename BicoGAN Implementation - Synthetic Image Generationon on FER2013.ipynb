{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15757,"status":"ok","timestamp":1662539533035,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"fatZmbjvVLgX","outputId":"3fa433db-3ddf-4db0-d6a2-ded517da9cfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["## If you are using the data by mounting the google drive, use the following :\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","##Ref:https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HaqFx3LETYkv"},"outputs":[],"source":["from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n","from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n","from keras.layers import MaxPooling2D, concatenate, Conv2DTranspose, Concatenate\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential, Model, load_model\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from keras import losses\n","from tensorflow.keras.utils import to_categorical\n","import keras.backend as K\n","\n","import imgaug as ia\n","import imgaug.augmenters as iaa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90,"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}}},"executionInfo":{"elapsed":16071,"status":"ok","timestamp":1662539587983,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"dRXT-CIADeZF","outputId":"f9dab0ed-ee12-408f-e8af-4030b0e1d69c"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-03cde10b-ccfc-48ee-8313-06ce991714f3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-03cde10b-ccfc-48ee-8313-06ce991714f3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"]},{"data":{"text/plain":["{'kaggle.json': b'{\"username\":\"manojkhurana\",\"key\":\"f998b8cd920f3206c2ebf0095cc280da\"}'}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["! pip install -q kaggle\n","from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2171,"status":"ok","timestamp":1662539594630,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"8qhEUAeyDei2","outputId":"2367837b-38c4-4d0f-e753-8069674f7b39"},"outputs":[{"name":"stdout","output_type":"stream","text":["ref                                                            title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n","-------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n","kaggleashwin/population-dataset                                World Population by Countries Dataset (1960-2021)    69KB  2022-08-31 05:30:26            956         44  1.0              \n","iamsouravbanerjee/house-rent-prediction-dataset                House Rent Prediction Dataset                        82KB  2022-08-20 13:49:03           8120        227  1.0              \n","iamsouravbanerjee/world-population-dataset                     World Population Dataset                             17KB  2022-08-31 11:20:04           2154         90  1.0              \n","sveta151/tiktok-popular-songs-2021                             TikTok popular songs 2021                            11KB  2022-08-22 11:02:34            704         31  1.0              \n","ariyoomotade/netflix-data-cleaning-analysis-and-visualization  Netflix Data: Cleaning, Analysis and Visualization  270KB  2022-08-26 09:25:43           2214         58  1.0              \n","deepcontractor/mcdonalds-india-menu-nutrition-facts            McDonald's India : Menu Nutrition Dataset             5KB  2022-07-28 17:08:52           5415        183  0.9411765        \n","arianazmoudeh/airbnbopendata                                   Airbnb Open Data                                     10MB  2022-08-01 15:58:10           3679        110  0.9705882        \n","estienneggx/spotify-unpopular-songs                            Spotify unpopular songs                             737KB  2022-09-04 22:10:41            409         24  1.0              \n","sveta151/tiktok-popular-songs-2019                             TikTok popular songs 2019                            45KB  2022-08-22 10:04:48            752         29  1.0              \n","deepcontractor/smoke-detection-dataset                         Smoke Detection Dataset                               2MB  2022-08-21 06:29:34           1331         48  1.0              \n","charanchandrasekaran/top-6-economies-in-the-world-by-gdp       Top 6 Economies in the world by GDP                  21KB  2022-08-26 05:57:26            460         26  0.9705882        \n","timmayer/covid-news-articles-2020-2022                         COVID News Articles (2020 - 2022)                   889MB  2022-08-31 17:22:48            253         28  0.9705882        \n","sveta151/tiktok-popular-songs-2022                             Tiktok popular songs 2022                            15KB  2022-08-22 11:20:57            937         43  1.0              \n","dansbecker/melbourne-housing-snapshot                          Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24          94721       1132  0.7058824        \n","tarundalal/100-richest-people-in-world                         100 Richest People In World                           3KB  2022-08-17 14:30:02           1165         52  1.0              \n","reihanenamdari/breast-cancer                                   Breast Cancer                                        43KB  2022-08-08 19:25:55           1680         64  1.0              \n","advaypatil/youtube-statistics                                  Youtube Statistics                                    2MB  2022-08-26 02:03:19            654         31  1.0              \n","gauravtopre/bank-customer-churn-dataset                        Bank Customer Churn Dataset                         187KB  2022-08-30 15:01:34            381         31  1.0              \n","infamouscoder/dataset-netflix-shows                            Dataset: NetFlix Shows                                1MB  2022-08-11 05:05:41           1762         68  1.0              \n","sandeepmajumdar/airbnbnyccleaned                               Airbnb-NYC-Cleaned                                    7MB  2022-08-25 06:13:12            339         24  1.0              \n"]}],"source":["! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","! kaggle datasets list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3977,"status":"ok","timestamp":1662539606167,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"v3It9e00DetR","outputId":"ebf333a6-f9ac-470e-cebf-c63793c6be15"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.6.15)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}],"source":["pip install opendatasets --upgrade\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9367,"status":"ok","timestamp":1662539617337,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"ZJNU8Np6EGhN","outputId":"14d01eef-101b-4cb9-8019-e1ac9c7db43d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading fer2013.zip to ./fer2013\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 96.6M/96.6M [00:04<00:00, 22.8MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["import opendatasets as od\n","import pandas\n","od.download(\n","    \"https://www.kaggle.com/datasets/deadskull7/fer2013/download?datasetVersionNumber=1\") "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":3406,"status":"ok","timestamp":1662539623931,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"fmcsl7qgTYoB","outputId":"19ead1b8-db52-4fba-cb5d-507c61d0b78a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d335fecf-edd9-4c90-a416-bb50f3e2d6b2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>emotion</th>\n","      <th>pixels</th>\n","      <th>Usage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n","      <td>Training</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d335fecf-edd9-4c90-a416-bb50f3e2d6b2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d335fecf-edd9-4c90-a416-bb50f3e2d6b2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d335fecf-edd9-4c90-a416-bb50f3e2d6b2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   emotion                                             pixels     Usage\n","0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n","1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n","2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n","3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n","4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('/content/fer2013/fer2013.csv')\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662539623931,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"8v3cQvpbTYqE","outputId":"7456b3b7-d41a-4807-93e9-3ee862bf444c"},"outputs":[{"data":{"text/plain":["3    8989\n","6    6198\n","4    6077\n","2    5121\n","0    4953\n","5    4002\n","1     547\n","Name: emotion, dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data.emotion.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51igbuw3TYsM"},"outputs":[],"source":["dic = {0:'Angry', 1:'disgust' , 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662539623931,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"9ThlSeQPTYu1","outputId":"3ad44444-b5b8-4db2-d9b6-46b28819d0a2"},"outputs":[{"data":{"text/plain":["3    8989\n","1    6198\n","4    6077\n","2    5121\n","0    4953\n","5    4002\n","Name: emotion, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data = data[data.emotion != 1]\n","data['emotion'] = data.emotion.replace(6, 1)\n","\n","data.emotion.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyTgGeNXTYxh"},"outputs":[],"source":["dic = {0:'Angry', 1:'Neutral', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HdVuaT0MTmFD"},"outputs":[],"source":["num_classes = 6\n","img_width = 48\n","img_height = 48"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31349,"status":"ok","timestamp":1662539661782,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"at2rViYrToAZ","outputId":"b24c418f-0f2b-4a6d-fdf2-42c1ccdc77a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(35340, 48, 48, 1)\n"]}],"source":["X = data['pixels']\n","y = data['emotion']\n","\n","X_train = []\n","for i in X:\n","    X_train.append([int(j) for j in i.split()])\n","\n","X_train = np.array(X_train)/255.0\n","\n","X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n","X_train = X_train.astype('float32')\n","\n","y_train = y.to_numpy().reshape(-1, 1)\n","\n","print(X_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"kX51Y8wzToEA","outputId":"d307875e-b8a1-4485-ad87-588ffdbe32ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["number of epochs: 35340\n","iteration: 0 , train shape: (35341, 48, 48, 1)\n","iteration: 100 , train shape: (35441, 48, 48, 1)\n","iteration: 200 , train shape: (35541, 48, 48, 1)\n","iteration: 300 , train shape: (35641, 48, 48, 1)\n","iteration: 400 , train shape: (35741, 48, 48, 1)\n","iteration: 500 , train shape: (35841, 48, 48, 1)\n","iteration: 600 , train shape: (35941, 48, 48, 1)\n","iteration: 700 , train shape: (36041, 48, 48, 1)\n","iteration: 800 , train shape: (36141, 48, 48, 1)\n","iteration: 900 , train shape: (36241, 48, 48, 1)\n","iteration: 1000 , train shape: (36341, 48, 48, 1)\n","iteration: 1100 , train shape: (36441, 48, 48, 1)\n","iteration: 1200 , train shape: (36541, 48, 48, 1)\n","iteration: 1300 , train shape: (36641, 48, 48, 1)\n","iteration: 1400 , train shape: (36741, 48, 48, 1)\n","iteration: 1500 , train shape: (36841, 48, 48, 1)\n","iteration: 1600 , train shape: (36941, 48, 48, 1)\n","iteration: 1700 , train shape: (37041, 48, 48, 1)\n","iteration: 1800 , train shape: (37141, 48, 48, 1)\n","iteration: 1900 , train shape: (37241, 48, 48, 1)\n","iteration: 2000 , train shape: (37341, 48, 48, 1)\n","iteration: 2100 , train shape: (37441, 48, 48, 1)\n","iteration: 2200 , train shape: (37541, 48, 48, 1)\n","iteration: 2300 , train shape: (37641, 48, 48, 1)\n","iteration: 2400 , train shape: (37741, 48, 48, 1)\n","iteration: 2500 , train shape: (37841, 48, 48, 1)\n","iteration: 2600 , train shape: (37941, 48, 48, 1)\n","iteration: 2700 , train shape: (38041, 48, 48, 1)\n","iteration: 2800 , train shape: (38141, 48, 48, 1)\n","iteration: 2900 , train shape: (38241, 48, 48, 1)\n","iteration: 3000 , train shape: (38341, 48, 48, 1)\n","iteration: 3100 , train shape: (38441, 48, 48, 1)\n","iteration: 3200 , train shape: (38541, 48, 48, 1)\n","iteration: 3300 , train shape: (38641, 48, 48, 1)\n","iteration: 3400 , train shape: (38741, 48, 48, 1)\n","iteration: 3500 , train shape: (38841, 48, 48, 1)\n","iteration: 3600 , train shape: (38941, 48, 48, 1)\n","iteration: 3700 , train shape: (39041, 48, 48, 1)\n","iteration: 3800 , train shape: (39141, 48, 48, 1)\n","iteration: 3900 , train shape: (39241, 48, 48, 1)\n","iteration: 4000 , train shape: (39341, 48, 48, 1)\n","iteration: 4100 , train shape: (39441, 48, 48, 1)\n","iteration: 4200 , train shape: (39541, 48, 48, 1)\n","iteration: 4300 , train shape: (39641, 48, 48, 1)\n","iteration: 4400 , train shape: (39741, 48, 48, 1)\n","iteration: 4500 , train shape: (39841, 48, 48, 1)\n","iteration: 4600 , train shape: (39941, 48, 48, 1)\n","iteration: 4700 , train shape: (40041, 48, 48, 1)\n","iteration: 4800 , train shape: (40141, 48, 48, 1)\n","iteration: 4900 , train shape: (40241, 48, 48, 1)\n","iteration: 5000 , train shape: (40341, 48, 48, 1)\n","iteration: 5100 , train shape: (40441, 48, 48, 1)\n","iteration: 5200 , train shape: (40541, 48, 48, 1)\n","iteration: 5300 , train shape: (40641, 48, 48, 1)\n","iteration: 5400 , train shape: (40741, 48, 48, 1)\n","iteration: 5500 , train shape: (40841, 48, 48, 1)\n","iteration: 5600 , train shape: (40941, 48, 48, 1)\n","iteration: 5700 , train shape: (41041, 48, 48, 1)\n","iteration: 5800 , train shape: (41141, 48, 48, 1)\n","iteration: 5900 , train shape: (41241, 48, 48, 1)\n","iteration: 6000 , train shape: (41341, 48, 48, 1)\n","iteration: 6100 , train shape: (41441, 48, 48, 1)\n","iteration: 6200 , train shape: (41541, 48, 48, 1)\n","iteration: 6300 , train shape: (41641, 48, 48, 1)\n","iteration: 6400 , train shape: (41741, 48, 48, 1)\n","iteration: 6500 , train shape: (41841, 48, 48, 1)\n","iteration: 6600 , train shape: (41941, 48, 48, 1)\n","iteration: 6700 , train shape: (42041, 48, 48, 1)\n","iteration: 6800 , train shape: (42141, 48, 48, 1)\n","iteration: 6900 , train shape: (42241, 48, 48, 1)\n","iteration: 7000 , train shape: (42341, 48, 48, 1)\n","iteration: 7100 , train shape: (42441, 48, 48, 1)\n","iteration: 7200 , train shape: (42541, 48, 48, 1)\n","iteration: 7300 , train shape: (42641, 48, 48, 1)\n","iteration: 7400 , train shape: (42741, 48, 48, 1)\n","iteration: 7500 , train shape: (42841, 48, 48, 1)\n","iteration: 7600 , train shape: (42941, 48, 48, 1)\n","iteration: 7700 , train shape: (43041, 48, 48, 1)\n","iteration: 7800 , train shape: (43141, 48, 48, 1)\n","iteration: 7900 , train shape: (43241, 48, 48, 1)\n","iteration: 8000 , train shape: (43341, 48, 48, 1)\n","iteration: 8100 , train shape: (43441, 48, 48, 1)\n","iteration: 8200 , train shape: (43541, 48, 48, 1)\n","iteration: 8300 , train shape: (43641, 48, 48, 1)\n","iteration: 8400 , train shape: (43741, 48, 48, 1)\n","iteration: 8500 , train shape: (43841, 48, 48, 1)\n","iteration: 8600 , train shape: (43941, 48, 48, 1)\n","iteration: 8700 , train shape: (44041, 48, 48, 1)\n","iteration: 8800 , train shape: (44141, 48, 48, 1)\n","iteration: 8900 , train shape: (44241, 48, 48, 1)\n","iteration: 9000 , train shape: (44341, 48, 48, 1)\n","iteration: 9100 , train shape: (44441, 48, 48, 1)\n","iteration: 9200 , train shape: (44541, 48, 48, 1)\n","iteration: 9300 , train shape: (44641, 48, 48, 1)\n","iteration: 9400 , train shape: (44741, 48, 48, 1)\n","iteration: 9500 , train shape: (44841, 48, 48, 1)\n","iteration: 9600 , train shape: (44941, 48, 48, 1)\n","iteration: 9700 , train shape: (45041, 48, 48, 1)\n","iteration: 9800 , train shape: (45141, 48, 48, 1)\n","iteration: 9900 , train shape: (45241, 48, 48, 1)\n","iteration: 10000 , train shape: (45341, 48, 48, 1)\n","iteration: 10100 , train shape: (45441, 48, 48, 1)\n","iteration: 10200 , train shape: (45541, 48, 48, 1)\n","iteration: 10300 , train shape: (45641, 48, 48, 1)\n","iteration: 10400 , train shape: (45741, 48, 48, 1)\n","iteration: 10500 , train shape: (45841, 48, 48, 1)\n","iteration: 10600 , train shape: (45941, 48, 48, 1)\n","iteration: 10700 , train shape: (46041, 48, 48, 1)\n","iteration: 10800 , train shape: (46141, 48, 48, 1)\n","iteration: 10900 , train shape: (46241, 48, 48, 1)\n","iteration: 11000 , train shape: (46341, 48, 48, 1)\n","iteration: 11100 , train shape: (46441, 48, 48, 1)\n","iteration: 11200 , train shape: (46541, 48, 48, 1)\n","iteration: 11300 , train shape: (46641, 48, 48, 1)\n","iteration: 11400 , train shape: (46741, 48, 48, 1)\n","iteration: 11500 , train shape: (46841, 48, 48, 1)\n","iteration: 11600 , train shape: (46941, 48, 48, 1)\n","iteration: 11700 , train shape: (47041, 48, 48, 1)\n","iteration: 11800 , train shape: (47141, 48, 48, 1)\n","iteration: 11900 , train shape: (47241, 48, 48, 1)\n","iteration: 12000 , train shape: (47341, 48, 48, 1)\n","iteration: 12100 , train shape: (47441, 48, 48, 1)\n","iteration: 12200 , train shape: (47541, 48, 48, 1)\n","iteration: 12300 , train shape: (47641, 48, 48, 1)\n","iteration: 12400 , train shape: (47741, 48, 48, 1)\n","iteration: 12500 , train shape: (47841, 48, 48, 1)\n","iteration: 12600 , train shape: (47941, 48, 48, 1)\n","iteration: 12700 , train shape: (48041, 48, 48, 1)\n","iteration: 12800 , train shape: (48141, 48, 48, 1)\n","iteration: 12900 , train shape: (48241, 48, 48, 1)\n","iteration: 13000 , train shape: (48341, 48, 48, 1)\n","iteration: 13100 , train shape: (48441, 48, 48, 1)\n","iteration: 13200 , train shape: (48541, 48, 48, 1)\n","iteration: 13300 , train shape: (48641, 48, 48, 1)\n","iteration: 13400 , train shape: (48741, 48, 48, 1)\n","iteration: 13500 , train shape: (48841, 48, 48, 1)\n","iteration: 13600 , train shape: (48941, 48, 48, 1)\n","iteration: 13700 , train shape: (49041, 48, 48, 1)\n","iteration: 13800 , train shape: (49141, 48, 48, 1)\n","iteration: 13900 , train shape: (49241, 48, 48, 1)\n","iteration: 14000 , train shape: (49341, 48, 48, 1)\n","iteration: 14100 , train shape: (49441, 48, 48, 1)\n","iteration: 14200 , train shape: (49541, 48, 48, 1)\n","iteration: 14300 , train shape: (49641, 48, 48, 1)\n","iteration: 14400 , train shape: (49741, 48, 48, 1)\n","iteration: 14500 , train shape: (49841, 48, 48, 1)\n","iteration: 14600 , train shape: (49941, 48, 48, 1)\n","iteration: 14700 , train shape: (50041, 48, 48, 1)\n","iteration: 14800 , train shape: (50141, 48, 48, 1)\n","iteration: 14900 , train shape: (50241, 48, 48, 1)\n","iteration: 15000 , train shape: (50341, 48, 48, 1)\n","iteration: 15100 , train shape: (50441, 48, 48, 1)\n","iteration: 15200 , train shape: (50541, 48, 48, 1)\n","iteration: 15300 , train shape: (50641, 48, 48, 1)\n","iteration: 15400 , train shape: (50741, 48, 48, 1)\n","iteration: 15500 , train shape: (50841, 48, 48, 1)\n","iteration: 15600 , train shape: (50941, 48, 48, 1)\n","iteration: 15700 , train shape: (51041, 48, 48, 1)\n","iteration: 15800 , train shape: (51141, 48, 48, 1)\n","iteration: 15900 , train shape: (51241, 48, 48, 1)\n","iteration: 16000 , train shape: (51341, 48, 48, 1)\n","iteration: 16100 , train shape: (51441, 48, 48, 1)\n","iteration: 16200 , train shape: (51541, 48, 48, 1)\n","iteration: 16300 , train shape: (51641, 48, 48, 1)\n","iteration: 16400 , train shape: (51741, 48, 48, 1)\n","iteration: 16500 , train shape: (51841, 48, 48, 1)\n","iteration: 16600 , train shape: (51941, 48, 48, 1)\n","iteration: 16700 , train shape: (52041, 48, 48, 1)\n","iteration: 16800 , train shape: (52141, 48, 48, 1)\n","iteration: 16900 , train shape: (52241, 48, 48, 1)\n","iteration: 17000 , train shape: (52341, 48, 48, 1)\n","iteration: 17100 , train shape: (52441, 48, 48, 1)\n","iteration: 17200 , train shape: (52541, 48, 48, 1)\n","iteration: 17300 , train shape: (52641, 48, 48, 1)\n","iteration: 17400 , train shape: (52741, 48, 48, 1)\n","iteration: 17500 , train shape: (52841, 48, 48, 1)\n","iteration: 17600 , train shape: (52941, 48, 48, 1)\n","iteration: 17700 , train shape: (53041, 48, 48, 1)\n","iteration: 17800 , train shape: (53141, 48, 48, 1)\n","iteration: 17900 , train shape: (53241, 48, 48, 1)\n","iteration: 18000 , train shape: (53341, 48, 48, 1)\n","iteration: 18100 , train shape: (53441, 48, 48, 1)\n","iteration: 18200 , train shape: (53541, 48, 48, 1)\n","iteration: 18300 , train shape: (53641, 48, 48, 1)\n","iteration: 18400 , train shape: (53741, 48, 48, 1)\n","iteration: 18500 , train shape: (53841, 48, 48, 1)\n","iteration: 18600 , train shape: (53941, 48, 48, 1)\n","iteration: 18700 , train shape: (54041, 48, 48, 1)\n","iteration: 18800 , train shape: (54141, 48, 48, 1)\n","iteration: 18900 , train shape: (54241, 48, 48, 1)\n","iteration: 19000 , train shape: (54341, 48, 48, 1)\n","iteration: 19100 , train shape: (54441, 48, 48, 1)\n","iteration: 19200 , train shape: (54541, 48, 48, 1)\n","iteration: 19300 , train shape: (54641, 48, 48, 1)\n","iteration: 19400 , train shape: (54741, 48, 48, 1)\n","iteration: 19500 , train shape: (54841, 48, 48, 1)\n","iteration: 19600 , train shape: (54941, 48, 48, 1)\n","iteration: 19700 , train shape: (55041, 48, 48, 1)\n","iteration: 19800 , train shape: (55141, 48, 48, 1)\n","iteration: 19900 , train shape: (55241, 48, 48, 1)\n","iteration: 20000 , train shape: (55341, 48, 48, 1)\n","iteration: 20100 , train shape: (55441, 48, 48, 1)\n","iteration: 20200 , train shape: (55541, 48, 48, 1)\n","iteration: 20300 , train shape: (55641, 48, 48, 1)\n","iteration: 20400 , train shape: (55741, 48, 48, 1)\n","iteration: 20500 , train shape: (55841, 48, 48, 1)\n","iteration: 20600 , train shape: (55941, 48, 48, 1)\n","iteration: 20700 , train shape: (56041, 48, 48, 1)\n","iteration: 20800 , train shape: (56141, 48, 48, 1)\n","iteration: 20900 , train shape: (56241, 48, 48, 1)\n","iteration: 21000 , train shape: (56341, 48, 48, 1)\n","iteration: 21100 , train shape: (56441, 48, 48, 1)\n","iteration: 21200 , train shape: (56541, 48, 48, 1)\n","iteration: 21300 , train shape: (56641, 48, 48, 1)\n","iteration: 21400 , train shape: (56741, 48, 48, 1)\n","iteration: 21500 , train shape: (56841, 48, 48, 1)\n","iteration: 21600 , train shape: (56941, 48, 48, 1)\n","iteration: 21700 , train shape: (57041, 48, 48, 1)\n","iteration: 21800 , train shape: (57141, 48, 48, 1)\n","iteration: 21900 , train shape: (57241, 48, 48, 1)\n","iteration: 22000 , train shape: (57341, 48, 48, 1)\n","iteration: 22100 , train shape: (57441, 48, 48, 1)\n","iteration: 22200 , train shape: (57541, 48, 48, 1)\n","iteration: 22300 , train shape: (57641, 48, 48, 1)\n","iteration: 22400 , train shape: (57741, 48, 48, 1)\n","iteration: 22500 , train shape: (57841, 48, 48, 1)\n","iteration: 22600 , train shape: (57941, 48, 48, 1)\n","iteration: 22700 , train shape: (58041, 48, 48, 1)\n","iteration: 22800 , train shape: (58141, 48, 48, 1)\n","iteration: 22900 , train shape: (58241, 48, 48, 1)\n","iteration: 23000 , train shape: (58341, 48, 48, 1)\n","iteration: 23100 , train shape: (58441, 48, 48, 1)\n","iteration: 23200 , train shape: (58541, 48, 48, 1)\n","iteration: 23300 , train shape: (58641, 48, 48, 1)\n","iteration: 23400 , train shape: (58741, 48, 48, 1)\n","iteration: 23500 , train shape: (58841, 48, 48, 1)\n","iteration: 23600 , train shape: (58941, 48, 48, 1)\n","iteration: 23700 , train shape: (59041, 48, 48, 1)\n","iteration: 23800 , train shape: (59141, 48, 48, 1)\n","iteration: 23900 , train shape: (59241, 48, 48, 1)\n","iteration: 24000 , train shape: (59341, 48, 48, 1)\n","iteration: 24100 , train shape: (59441, 48, 48, 1)\n","iteration: 24200 , train shape: (59541, 48, 48, 1)\n","iteration: 24300 , train shape: (59641, 48, 48, 1)\n","iteration: 24400 , train shape: (59741, 48, 48, 1)\n","iteration: 24500 , train shape: (59841, 48, 48, 1)\n","iteration: 24600 , train shape: (59941, 48, 48, 1)\n","iteration: 24700 , train shape: (60041, 48, 48, 1)\n","iteration: 24800 , train shape: (60141, 48, 48, 1)\n","iteration: 24900 , train shape: (60241, 48, 48, 1)\n","iteration: 25000 , train shape: (60341, 48, 48, 1)\n","iteration: 25100 , train shape: (60441, 48, 48, 1)\n","iteration: 25200 , train shape: (60541, 48, 48, 1)\n","iteration: 25300 , train shape: (60641, 48, 48, 1)\n","iteration: 25400 , train shape: (60741, 48, 48, 1)\n","iteration: 25500 , train shape: (60841, 48, 48, 1)\n","iteration: 25600 , train shape: (60941, 48, 48, 1)\n","iteration: 25700 , train shape: (61041, 48, 48, 1)\n","iteration: 25800 , train shape: (61141, 48, 48, 1)\n","iteration: 25900 , train shape: (61241, 48, 48, 1)\n","iteration: 26000 , train shape: (61341, 48, 48, 1)\n","iteration: 26100 , train shape: (61441, 48, 48, 1)\n","iteration: 26200 , train shape: (61541, 48, 48, 1)\n","iteration: 26300 , train shape: (61641, 48, 48, 1)\n","iteration: 26400 , train shape: (61741, 48, 48, 1)\n","iteration: 26500 , train shape: (61841, 48, 48, 1)\n","iteration: 26600 , train shape: (61941, 48, 48, 1)\n","iteration: 26700 , train shape: (62041, 48, 48, 1)\n","iteration: 26800 , train shape: (62141, 48, 48, 1)\n","iteration: 26900 , train shape: (62241, 48, 48, 1)\n","iteration: 27000 , train shape: (62341, 48, 48, 1)\n","iteration: 27100 , train shape: (62441, 48, 48, 1)\n","iteration: 27200 , train shape: (62541, 48, 48, 1)\n","iteration: 27300 , train shape: (62641, 48, 48, 1)\n","iteration: 27400 , train shape: (62741, 48, 48, 1)\n","iteration: 27500 , train shape: (62841, 48, 48, 1)\n","iteration: 27600 , train shape: (62941, 48, 48, 1)\n","iteration: 27700 , train shape: (63041, 48, 48, 1)\n","iteration: 27800 , train shape: (63141, 48, 48, 1)\n","iteration: 27900 , train shape: (63241, 48, 48, 1)\n","iteration: 28000 , train shape: (63341, 48, 48, 1)\n","iteration: 28100 , train shape: (63441, 48, 48, 1)\n","iteration: 28200 , train shape: (63541, 48, 48, 1)\n","iteration: 28300 , train shape: (63641, 48, 48, 1)\n","iteration: 28400 , train shape: (63741, 48, 48, 1)\n","iteration: 28500 , train shape: (63841, 48, 48, 1)\n","iteration: 28600 , train shape: (63941, 48, 48, 1)\n","iteration: 28700 , train shape: (64041, 48, 48, 1)\n","iteration: 28800 , train shape: (64141, 48, 48, 1)\n","iteration: 28900 , train shape: (64241, 48, 48, 1)\n","iteration: 29000 , train shape: (64341, 48, 48, 1)\n","iteration: 29100 , train shape: (64441, 48, 48, 1)\n","iteration: 29200 , train shape: (64541, 48, 48, 1)\n","iteration: 29300 , train shape: (64641, 48, 48, 1)\n","iteration: 29400 , train shape: (64741, 48, 48, 1)\n","iteration: 29500 , train shape: (64841, 48, 48, 1)\n","iteration: 29600 , train shape: (64941, 48, 48, 1)\n","iteration: 29700 , train shape: (65041, 48, 48, 1)\n","iteration: 29800 , train shape: (65141, 48, 48, 1)\n","iteration: 29900 , train shape: (65241, 48, 48, 1)\n","iteration: 30000 , train shape: (65341, 48, 48, 1)\n","iteration: 30100 , train shape: (65441, 48, 48, 1)\n","iteration: 30200 , train shape: (65541, 48, 48, 1)\n","iteration: 30300 , train shape: (65641, 48, 48, 1)\n","iteration: 30400 , train shape: (65741, 48, 48, 1)\n","iteration: 30500 , train shape: (65841, 48, 48, 1)\n","iteration: 30600 , train shape: (65941, 48, 48, 1)\n","iteration: 30700 , train shape: (66041, 48, 48, 1)\n","iteration: 30800 , train shape: (66141, 48, 48, 1)\n","iteration: 30900 , train shape: (66241, 48, 48, 1)\n","iteration: 31000 , train shape: (66341, 48, 48, 1)\n","iteration: 31100 , train shape: (66441, 48, 48, 1)\n","iteration: 31200 , train shape: (66541, 48, 48, 1)\n","iteration: 31300 , train shape: (66641, 48, 48, 1)\n","iteration: 31400 , train shape: (66741, 48, 48, 1)\n","iteration: 31500 , train shape: (66841, 48, 48, 1)\n","iteration: 31600 , train shape: (66941, 48, 48, 1)\n","iteration: 31700 , train shape: (67041, 48, 48, 1)\n","iteration: 31800 , train shape: (67141, 48, 48, 1)\n","iteration: 31900 , train shape: (67241, 48, 48, 1)\n","iteration: 32000 , train shape: (67341, 48, 48, 1)\n","iteration: 32100 , train shape: (67441, 48, 48, 1)\n","iteration: 32200 , train shape: (67541, 48, 48, 1)\n","iteration: 32300 , train shape: (67641, 48, 48, 1)\n","iteration: 32400 , train shape: (67741, 48, 48, 1)\n","iteration: 32500 , train shape: (67841, 48, 48, 1)\n","iteration: 32600 , train shape: (67941, 48, 48, 1)\n","iteration: 32700 , train shape: (68041, 48, 48, 1)\n","iteration: 32800 , train shape: (68141, 48, 48, 1)\n","iteration: 32900 , train shape: (68241, 48, 48, 1)\n","iteration: 33000 , train shape: (68341, 48, 48, 1)\n","iteration: 33100 , train shape: (68441, 48, 48, 1)\n","iteration: 33200 , train shape: (68541, 48, 48, 1)\n","iteration: 33300 , train shape: (68641, 48, 48, 1)\n","iteration: 33400 , train shape: (68741, 48, 48, 1)\n","iteration: 33500 , train shape: (68841, 48, 48, 1)\n","iteration: 33600 , train shape: (68941, 48, 48, 1)\n","iteration: 33700 , train shape: (69041, 48, 48, 1)\n","iteration: 33800 , train shape: (69141, 48, 48, 1)\n","iteration: 33900 , train shape: (69241, 48, 48, 1)\n","iteration: 34000 , train shape: (69341, 48, 48, 1)\n","iteration: 34100 , train shape: (69441, 48, 48, 1)\n","iteration: 34200 , train shape: (69541, 48, 48, 1)\n","iteration: 34300 , train shape: (69641, 48, 48, 1)\n","iteration: 34400 , train shape: (69741, 48, 48, 1)\n","iteration: 34500 , train shape: (69841, 48, 48, 1)\n","iteration: 34600 , train shape: (69941, 48, 48, 1)\n","iteration: 34700 , train shape: (70041, 48, 48, 1)\n","iteration: 34800 , train shape: (70141, 48, 48, 1)\n","iteration: 34900 , train shape: (70241, 48, 48, 1)\n","iteration: 35000 , train shape: (70341, 48, 48, 1)\n","iteration: 35100 , train shape: (70441, 48, 48, 1)\n","iteration: 35200 , train shape: (70541, 48, 48, 1)\n","iteration: 35300 , train shape: (70641, 48, 48, 1)\n"]}],"source":["epochs = X_train.shape[0]\n","print(\"number of epochs:\", epochs)\n","\n","X_train_aug = X_train\n","y_train_aug = y_train\n","\n","for k in range(epochs):\n","  img = X_train[k]\n","  emotion = y_train[k]\n","  contrasted_images = []\n","  emotions_list = []\n","\n","  contrast = iaa.Affine(rotate=(-50, 30))\n","  contrast_image = contrast.augment_image(img)\n","  contrasted_images.append(contrast_image)\n","\n","  contrasted_images = np.array(contrasted_images)\n","  emotions_list = np.array(emotions_list)\n","  X_train_aug = np.concatenate((X_train_aug, contrasted_images), axis=0)\n","  emotions_list = [emotion]\n","  y_train_aug = np.concatenate((y_train_aug, emotions_list), axis=0)\n","\n","  if k % 100 == 0:\n","    print (\"iteration:\" , k,\", train shape:\", X_train_aug.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KetGg5GXToHm","outputId":"da353dd3-1857-4685-9e72-531ecb9fc9e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_aug shape: (70680, 48, 48, 1)\n","y_train_aug shape: (70680, 1)\n"]}],"source":["print(\"X_train_aug shape:\", X_train_aug.shape)\n","print(\"y_train_aug shape:\", y_train_aug.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2V-S3oWmA08A"},"outputs":[],"source":["#np.save(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /X_train_aug\", X_train_aug)\n","#np.save(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /y_train_aug\", y_train_aug)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":543,"status":"error","timestamp":1662539475193,"user":{"displayName":"p k","userId":"13079450723546894145"},"user_tz":-330},"id":"LVRaEjr9zeWR","outputId":"d8b6a114-5a7d-4680-f589-52e480458811"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ae15009a5191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /X_train_aug.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /y_train_aug.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /X_train_aug.npy'"]}],"source":["#X_train_aug=np.load(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /X_train_aug.npy\")\n","#y_train_aug=np.load(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /y_train_aug.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u0OTGT0DToKo"},"outputs":[],"source":["class BiCoGAN():\n","    def __init__(self):\n","        # Input shape\n","        self.img_rows = 48\n","        self.img_cols = 48\n","        self.channels = 1\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.num_classes = 6\n","        self.latent_dim = 100\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        print(self.discriminator.summary())\n","        plot_model(self.discriminator, show_shapes=True)\n","        self.discriminator.compile(loss=['binary_crossentropy'],\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # Build the encoder\n","        self.encoder = self.build_encoder()\n","\n","        # The generator takes noise and the target label as input\n","        # and generates the corresponding image of that label\n","        label = Input(shape=(1,))\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # Generate image from sampled noise\n","        z = Input(shape=(self.latent_dim, ))\n","        img_ = self.generator([z, label])\n","\n","        # Encode image\n","        img = Input(shape=self.img_shape)\n","        z_ = self.encoder(img)\n","\n","        # Latent -> img is fake, and img -> latent is valid\n","        fake = self.discriminator([z, img_, label])\n","        valid = self.discriminator([z_, img, label])\n","\n","        # Set up and compile the combined model\n","        # Trains generator to fool the discriminator\n","        self.bicogan_generator = Model([z, img, label], [fake, valid])\n","        self.bicogan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n","            optimizer=optimizer)\n","\n","    def build_encoder(self):\n","        model = Sequential()\n","\n","        model.add(Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=self.img_shape))\n","        model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n","        model.add(BatchNormalization(momentum=0.9))\n","        model.add(Conv2D(256, (5,5), strides=(2,2), padding='same'))\n","        model.add(BatchNormalization(momentum=0.9))\n","        model.add(Conv2D(512, (5,5), strides=(2,2), padding='same'))\n","        model.add(BatchNormalization(momentum=0.9))\n","        model.add(Flatten())\n","        model.add(Dense(self.latent_dim))\n","\n","        print('encoder')\n","        model.summary()\n","\n","        img = Input(shape=self.img_shape)\n","        z = model(img)\n","\n","        return Model(img, z)\n","\n","    def build_generator(self):\n","\n","        model = Sequential()\n","        # foundation for 12x12 image\n","        n_nodes = 128 * 12 * 12\n","        model.add(Dense(n_nodes, input_dim=self.latent_dim))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Reshape((12, 12, 128)))\n","        # upsample to 24x24\n","        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","        model.add(LeakyReLU(alpha=0.2))\n","        # upsample to 48x48\n","        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","        model.add(LeakyReLU(alpha=0.2))\n","        # generate\n","        model.add(Conv2D(1, (12, 12), activation='tanh', padding='same'))\n","\n","        print('generator')\n","        model.summary()\n","\n","        z = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,), dtype='int32')\n","        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n","\n","        model_input = multiply([z, label_embedding])\n","        img = model(model_input)\n","\n","        return Model([z, label], img)\n","\n","\n","    def build_discriminator(self):\n","        xi = Input(self.img_shape)\n","        zi = Input(self.latent_dim)\n","        label = Input(shape=(1,), dtype='int32')\n","\n","        xn = Conv2D(128, (5,5), padding='same')(xi)\n","        xn = LeakyReLU(alpha=0.2)(xn)\n","        # downsample to 24x24\n","        xn = Conv2D(128, (5,5), strides=(2,2), padding='same')(xn)\n","        xn = LeakyReLU(alpha=0.2)(xn)\n","        # downsample to 12x12\n","        xn = Conv2D(128, (5,5), strides=(2,2), padding='same')(xn)\n","        xn = LeakyReLU(alpha=0.2)(xn)\n","        # downsample to 6x6\n","        xn = Conv2D(128, (5,5), strides=(2,2), padding='same')(xn)\n","        xn = LeakyReLU(alpha=0.2)(xn)\n","        # downsample to 3x3\n","        xn = Conv2D(128, (5,5), strides=(2,2), padding='same')(xn)\n","        xn = LeakyReLU(alpha=0.2)(xn)\n","        # classifier\n","        xn = Flatten()(xn)\n","        zn = Flatten()(zi)\n","\n","        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n","\n","        nn = concatenate([zn, xn, label_embedding])\n","        nn = Dense(1, activation='sigmoid')(nn)\n","\n","        return Model([zi, xi, label], nn, name='discriminator')\n","\n","\n","    def train(self, epochs, batch_size=128, sample_interval=50):\n","        \n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random batch of images and encode\n","            idx = np.random.randint(0, X_train_aug.shape[0], batch_size)\n","            imgs, labels = X_train_aug[idx], y_train_aug[idx]\n","            z_ = self.encoder.predict(imgs)\n","\n","            # Sample noise and generate img\n","            z = np.random.normal(0, 1, (batch_size, 100))\n","            imgs_ = self.generator.predict([z, labels])\n","\n","            # Train the discriminator (img -> z is valid, z -> img is fake)\n","            d_loss_real = self.discriminator.train_on_batch([z_, imgs, labels], valid)\n","            d_loss_fake = self.discriminator.train_on_batch([z, imgs_, labels], fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            # Condition on labels\n","            sampled_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n","\n","            # Train the generator\n","            g_loss = self.bicogan_generator.train_on_batch([z, imgs, sampled_labels], [valid, fake])\n","\n","            # Plot the progress\n","            if epoch%20 == 0:\n","              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0]))\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                self.sample_images(epoch)\n","\n","\n","    def sample_images(self, epoch):\n","          r, c = 1, 6\n","          noise = np.random.normal(0, 1, (r * c, 100))\n","          sampled_labels = np.arange(0, 6).reshape(-1, 1)\n","\n","          gen_imgs = self.generator.predict([noise, sampled_labels])\n","\n","          # Rescale images 0 - 1\n","          gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","          fig, axs = plt.subplots(r, c)\n","          cnt = 0\n","          for j in range(c):\n","              axs[j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n","              axs[j].set_title(\"%s\" % dic[sampled_labels[cnt][0]])\n","              axs[j].axis('off')\n","              cnt += 1\n","          fig.savefig(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/FER2013 /images/%d.png\" % epoch)\n","          plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSHWjHW3ToN7"},"outputs":[],"source":["if __name__ == '__main__':\n","    bicogan = BiCoGAN()\n","    bicogan.train(epochs=18610, batch_size=128, sample_interval=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0v3CFPUQLloV"},"outputs":[],"source":["bicogan.discriminator.save(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/discriminatorTrained.h5\")\n","bicogan.generator.save(\"/content/gdrive/MyDrive/Colab Notebooks/Facial Expression Recognition Thesis/generatorTrained.h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1QrLhxB0S_5WUjajv2BTjhYa2R2eXcDZ3","authorship_tag":"ABX9TyM5caCthPg3CW4GCmqlRG0+"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}